{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff570f5-e6be-42dc-bca2-592e1b4e2be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database & table created\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"database.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS pdf_files (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pdf_name TEXT,\n",
    "    pdf_path TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ Database & table created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb381bc-9dd2-4f26-92cb-31d02a0e55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All PDF files saved in database\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "pdf_folder = \"pdfs\"\n",
    "\n",
    "conn = sqlite3.connect(\"database.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for file in os.listdir(pdf_folder):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_folder, file)\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO pdf_files (pdf_name, pdf_path) VALUES (?, ?)\",\n",
    "            (file, file_path)\n",
    "        )\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ All PDF files saved in database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a159d5-590f-46b1-ab06-3bda9d40949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'chatbot_data_1.pdf', 'pdfs\\\\chatbot_data_1.pdf')\n",
      "(2, 'chatbot_data_10.pdf', 'pdfs\\\\chatbot_data_10.pdf')\n",
      "(3, 'chatbot_data_2.pdf', 'pdfs\\\\chatbot_data_2.pdf')\n",
      "(4, 'chatbot_data_3.pdf', 'pdfs\\\\chatbot_data_3.pdf')\n",
      "(5, 'chatbot_data_4.pdf', 'pdfs\\\\chatbot_data_4.pdf')\n",
      "(6, 'chatbot_data_5.pdf', 'pdfs\\\\chatbot_data_5.pdf')\n",
      "(7, 'chatbot_data_6.pdf', 'pdfs\\\\chatbot_data_6.pdf')\n",
      "(8, 'chatbot_data_7.pdf', 'pdfs\\\\chatbot_data_7.pdf')\n",
      "(9, 'chatbot_data_8.pdf', 'pdfs\\\\chatbot_data_8.pdf')\n",
      "(10, 'chatbot_data_9.pdf', 'pdfs\\\\chatbot_data_9.pdf')\n",
      "(11, 'chatbot_data_1.pdf', 'pdfs\\\\chatbot_data_1.pdf')\n",
      "(12, 'chatbot_data_10.pdf', 'pdfs\\\\chatbot_data_10.pdf')\n",
      "(13, 'chatbot_data_2.pdf', 'pdfs\\\\chatbot_data_2.pdf')\n",
      "(14, 'chatbot_data_3.pdf', 'pdfs\\\\chatbot_data_3.pdf')\n",
      "(15, 'chatbot_data_4.pdf', 'pdfs\\\\chatbot_data_4.pdf')\n",
      "(16, 'chatbot_data_5.pdf', 'pdfs\\\\chatbot_data_5.pdf')\n",
      "(17, 'chatbot_data_6.pdf', 'pdfs\\\\chatbot_data_6.pdf')\n",
      "(18, 'chatbot_data_7.pdf', 'pdfs\\\\chatbot_data_7.pdf')\n",
      "(19, 'chatbot_data_8.pdf', 'pdfs\\\\chatbot_data_8.pdf')\n",
      "(20, 'chatbot_data_9.pdf', 'pdfs\\\\chatbot_data_9.pdf')\n",
      "(21, 'chatbot_data_1.pdf', 'pdfs\\\\chatbot_data_1.pdf')\n",
      "(22, 'chatbot_data_10.pdf', 'pdfs\\\\chatbot_data_10.pdf')\n",
      "(23, 'chatbot_data_2.pdf', 'pdfs\\\\chatbot_data_2.pdf')\n",
      "(24, 'chatbot_data_3.pdf', 'pdfs\\\\chatbot_data_3.pdf')\n",
      "(25, 'chatbot_data_4.pdf', 'pdfs\\\\chatbot_data_4.pdf')\n",
      "(26, 'chatbot_data_5.pdf', 'pdfs\\\\chatbot_data_5.pdf')\n",
      "(27, 'chatbot_data_6.pdf', 'pdfs\\\\chatbot_data_6.pdf')\n",
      "(28, 'chatbot_data_7.pdf', 'pdfs\\\\chatbot_data_7.pdf')\n",
      "(29, 'chatbot_data_8.pdf', 'pdfs\\\\chatbot_data_8.pdf')\n",
      "(30, 'chatbot_data_9.pdf', 'pdfs\\\\chatbot_data_9.pdf')\n",
      "(31, 'chatbot_data_1.pdf', 'pdfs\\\\chatbot_data_1.pdf')\n",
      "(32, 'chatbot_data_10.pdf', 'pdfs\\\\chatbot_data_10.pdf')\n",
      "(33, 'chatbot_data_2.pdf', 'pdfs\\\\chatbot_data_2.pdf')\n",
      "(34, 'chatbot_data_3.pdf', 'pdfs\\\\chatbot_data_3.pdf')\n",
      "(35, 'chatbot_data_4.pdf', 'pdfs\\\\chatbot_data_4.pdf')\n",
      "(36, 'chatbot_data_5.pdf', 'pdfs\\\\chatbot_data_5.pdf')\n",
      "(37, 'chatbot_data_6.pdf', 'pdfs\\\\chatbot_data_6.pdf')\n",
      "(38, 'chatbot_data_7.pdf', 'pdfs\\\\chatbot_data_7.pdf')\n",
      "(39, 'chatbot_data_8.pdf', 'pdfs\\\\chatbot_data_8.pdf')\n",
      "(40, 'chatbot_data_9.pdf', 'pdfs\\\\chatbot_data_9.pdf')\n",
      "(41, 'chatbot_data_1.pdf', 'pdfs\\\\chatbot_data_1.pdf')\n",
      "(42, 'chatbot_data_10.pdf', 'pdfs\\\\chatbot_data_10.pdf')\n",
      "(43, 'chatbot_data_2.pdf', 'pdfs\\\\chatbot_data_2.pdf')\n",
      "(44, 'chatbot_data_3.pdf', 'pdfs\\\\chatbot_data_3.pdf')\n",
      "(45, 'chatbot_data_4.pdf', 'pdfs\\\\chatbot_data_4.pdf')\n",
      "(46, 'chatbot_data_5.pdf', 'pdfs\\\\chatbot_data_5.pdf')\n",
      "(47, 'chatbot_data_6.pdf', 'pdfs\\\\chatbot_data_6.pdf')\n",
      "(48, 'chatbot_data_7.pdf', 'pdfs\\\\chatbot_data_7.pdf')\n",
      "(49, 'chatbot_data_8.pdf', 'pdfs\\\\chatbot_data_8.pdf')\n",
      "(50, 'chatbot_data_9.pdf', 'pdfs\\\\chatbot_data_9.pdf')\n",
      "(51, 'chatbot_data_1.pdf', 'pdfs\\\\chatbot_data_1.pdf')\n",
      "(52, 'chatbot_data_10.pdf', 'pdfs\\\\chatbot_data_10.pdf')\n",
      "(53, 'chatbot_data_2.pdf', 'pdfs\\\\chatbot_data_2.pdf')\n",
      "(54, 'chatbot_data_3.pdf', 'pdfs\\\\chatbot_data_3.pdf')\n",
      "(55, 'chatbot_data_4.pdf', 'pdfs\\\\chatbot_data_4.pdf')\n",
      "(56, 'chatbot_data_5.pdf', 'pdfs\\\\chatbot_data_5.pdf')\n",
      "(57, 'chatbot_data_6.pdf', 'pdfs\\\\chatbot_data_6.pdf')\n",
      "(58, 'chatbot_data_7.pdf', 'pdfs\\\\chatbot_data_7.pdf')\n",
      "(59, 'chatbot_data_8.pdf', 'pdfs\\\\chatbot_data_8.pdf')\n",
      "(60, 'chatbot_data_9.pdf', 'pdfs\\\\chatbot_data_9.pdf')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"database.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM pdf_files\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadff4d1-738a-44d1-820f-d1eb51183794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>pdf_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>chatbot_data_1.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>chatbot_data_10.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_10.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>chatbot_data_2.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>chatbot_data_3.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>chatbot_data_4.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>chatbot_data_5.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_5.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>chatbot_data_6.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_6.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>chatbot_data_7.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_7.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>chatbot_data_8.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_8.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>chatbot_data_9.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_9.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>chatbot_data_1.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>chatbot_data_10.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_10.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>chatbot_data_2.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>chatbot_data_3.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>chatbot_data_4.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>chatbot_data_5.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_5.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>chatbot_data_6.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_6.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>chatbot_data_7.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_7.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>chatbot_data_8.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_8.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>chatbot_data_9.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_9.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>chatbot_data_1.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>chatbot_data_10.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_10.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>chatbot_data_2.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>chatbot_data_3.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>chatbot_data_4.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>chatbot_data_5.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_5.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>chatbot_data_6.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_6.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>chatbot_data_7.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_7.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>chatbot_data_8.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_8.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>chatbot_data_9.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_9.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>chatbot_data_1.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>chatbot_data_10.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_10.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>chatbot_data_2.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>chatbot_data_3.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>chatbot_data_4.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>chatbot_data_5.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_5.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>chatbot_data_6.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_6.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>chatbot_data_7.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_7.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>chatbot_data_8.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_8.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>chatbot_data_9.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_9.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>chatbot_data_1.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>chatbot_data_10.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_10.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>chatbot_data_2.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>chatbot_data_3.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>chatbot_data_4.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>chatbot_data_5.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_5.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>chatbot_data_6.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_6.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>chatbot_data_7.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_7.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>chatbot_data_8.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_8.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>chatbot_data_9.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_9.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>chatbot_data_1.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>chatbot_data_10.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_10.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>chatbot_data_2.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>chatbot_data_3.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>chatbot_data_4.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_4.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>chatbot_data_5.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_5.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>chatbot_data_6.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_6.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>chatbot_data_7.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_7.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>chatbot_data_8.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_8.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>chatbot_data_9.pdf</td>\n",
       "      <td>pdfs\\chatbot_data_9.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id             pdf_name                  pdf_path\n",
       "0    1   chatbot_data_1.pdf   pdfs\\chatbot_data_1.pdf\n",
       "1    2  chatbot_data_10.pdf  pdfs\\chatbot_data_10.pdf\n",
       "2    3   chatbot_data_2.pdf   pdfs\\chatbot_data_2.pdf\n",
       "3    4   chatbot_data_3.pdf   pdfs\\chatbot_data_3.pdf\n",
       "4    5   chatbot_data_4.pdf   pdfs\\chatbot_data_4.pdf\n",
       "5    6   chatbot_data_5.pdf   pdfs\\chatbot_data_5.pdf\n",
       "6    7   chatbot_data_6.pdf   pdfs\\chatbot_data_6.pdf\n",
       "7    8   chatbot_data_7.pdf   pdfs\\chatbot_data_7.pdf\n",
       "8    9   chatbot_data_8.pdf   pdfs\\chatbot_data_8.pdf\n",
       "9   10   chatbot_data_9.pdf   pdfs\\chatbot_data_9.pdf\n",
       "10  11   chatbot_data_1.pdf   pdfs\\chatbot_data_1.pdf\n",
       "11  12  chatbot_data_10.pdf  pdfs\\chatbot_data_10.pdf\n",
       "12  13   chatbot_data_2.pdf   pdfs\\chatbot_data_2.pdf\n",
       "13  14   chatbot_data_3.pdf   pdfs\\chatbot_data_3.pdf\n",
       "14  15   chatbot_data_4.pdf   pdfs\\chatbot_data_4.pdf\n",
       "15  16   chatbot_data_5.pdf   pdfs\\chatbot_data_5.pdf\n",
       "16  17   chatbot_data_6.pdf   pdfs\\chatbot_data_6.pdf\n",
       "17  18   chatbot_data_7.pdf   pdfs\\chatbot_data_7.pdf\n",
       "18  19   chatbot_data_8.pdf   pdfs\\chatbot_data_8.pdf\n",
       "19  20   chatbot_data_9.pdf   pdfs\\chatbot_data_9.pdf\n",
       "20  21   chatbot_data_1.pdf   pdfs\\chatbot_data_1.pdf\n",
       "21  22  chatbot_data_10.pdf  pdfs\\chatbot_data_10.pdf\n",
       "22  23   chatbot_data_2.pdf   pdfs\\chatbot_data_2.pdf\n",
       "23  24   chatbot_data_3.pdf   pdfs\\chatbot_data_3.pdf\n",
       "24  25   chatbot_data_4.pdf   pdfs\\chatbot_data_4.pdf\n",
       "25  26   chatbot_data_5.pdf   pdfs\\chatbot_data_5.pdf\n",
       "26  27   chatbot_data_6.pdf   pdfs\\chatbot_data_6.pdf\n",
       "27  28   chatbot_data_7.pdf   pdfs\\chatbot_data_7.pdf\n",
       "28  29   chatbot_data_8.pdf   pdfs\\chatbot_data_8.pdf\n",
       "29  30   chatbot_data_9.pdf   pdfs\\chatbot_data_9.pdf\n",
       "30  31   chatbot_data_1.pdf   pdfs\\chatbot_data_1.pdf\n",
       "31  32  chatbot_data_10.pdf  pdfs\\chatbot_data_10.pdf\n",
       "32  33   chatbot_data_2.pdf   pdfs\\chatbot_data_2.pdf\n",
       "33  34   chatbot_data_3.pdf   pdfs\\chatbot_data_3.pdf\n",
       "34  35   chatbot_data_4.pdf   pdfs\\chatbot_data_4.pdf\n",
       "35  36   chatbot_data_5.pdf   pdfs\\chatbot_data_5.pdf\n",
       "36  37   chatbot_data_6.pdf   pdfs\\chatbot_data_6.pdf\n",
       "37  38   chatbot_data_7.pdf   pdfs\\chatbot_data_7.pdf\n",
       "38  39   chatbot_data_8.pdf   pdfs\\chatbot_data_8.pdf\n",
       "39  40   chatbot_data_9.pdf   pdfs\\chatbot_data_9.pdf\n",
       "40  41   chatbot_data_1.pdf   pdfs\\chatbot_data_1.pdf\n",
       "41  42  chatbot_data_10.pdf  pdfs\\chatbot_data_10.pdf\n",
       "42  43   chatbot_data_2.pdf   pdfs\\chatbot_data_2.pdf\n",
       "43  44   chatbot_data_3.pdf   pdfs\\chatbot_data_3.pdf\n",
       "44  45   chatbot_data_4.pdf   pdfs\\chatbot_data_4.pdf\n",
       "45  46   chatbot_data_5.pdf   pdfs\\chatbot_data_5.pdf\n",
       "46  47   chatbot_data_6.pdf   pdfs\\chatbot_data_6.pdf\n",
       "47  48   chatbot_data_7.pdf   pdfs\\chatbot_data_7.pdf\n",
       "48  49   chatbot_data_8.pdf   pdfs\\chatbot_data_8.pdf\n",
       "49  50   chatbot_data_9.pdf   pdfs\\chatbot_data_9.pdf\n",
       "50  51   chatbot_data_1.pdf   pdfs\\chatbot_data_1.pdf\n",
       "51  52  chatbot_data_10.pdf  pdfs\\chatbot_data_10.pdf\n",
       "52  53   chatbot_data_2.pdf   pdfs\\chatbot_data_2.pdf\n",
       "53  54   chatbot_data_3.pdf   pdfs\\chatbot_data_3.pdf\n",
       "54  55   chatbot_data_4.pdf   pdfs\\chatbot_data_4.pdf\n",
       "55  56   chatbot_data_5.pdf   pdfs\\chatbot_data_5.pdf\n",
       "56  57   chatbot_data_6.pdf   pdfs\\chatbot_data_6.pdf\n",
       "57  58   chatbot_data_7.pdf   pdfs\\chatbot_data_7.pdf\n",
       "58  59   chatbot_data_8.pdf   pdfs\\chatbot_data_8.pdf\n",
       "59  60   chatbot_data_9.pdf   pdfs\\chatbot_data_9.pdf"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"database.db\")\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM pdf_files\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5dfad04-c34c-450b-9c3a-5d167abc3b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\rahul\\anaconda3\\lib\\site-packages (6.5.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.13.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\rahul\\anaconda3\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (1.2.6)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.12.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf langchain faiss-cpu sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfdbfe4-02f9-4b02-afc3-16690e9a7485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pdfs\\\\chatbot_data_1.pdf',),\n",
       " ('pdfs\\\\chatbot_data_10.pdf',),\n",
       " ('pdfs\\\\chatbot_data_2.pdf',),\n",
       " ('pdfs\\\\chatbot_data_3.pdf',),\n",
       " ('pdfs\\\\chatbot_data_4.pdf',),\n",
       " ('pdfs\\\\chatbot_data_5.pdf',),\n",
       " ('pdfs\\\\chatbot_data_6.pdf',),\n",
       " ('pdfs\\\\chatbot_data_7.pdf',),\n",
       " ('pdfs\\\\chatbot_data_8.pdf',),\n",
       " ('pdfs\\\\chatbot_data_9.pdf',),\n",
       " ('pdfs\\\\chatbot_data_1.pdf',),\n",
       " ('pdfs\\\\chatbot_data_10.pdf',),\n",
       " ('pdfs\\\\chatbot_data_2.pdf',),\n",
       " ('pdfs\\\\chatbot_data_3.pdf',),\n",
       " ('pdfs\\\\chatbot_data_4.pdf',),\n",
       " ('pdfs\\\\chatbot_data_5.pdf',),\n",
       " ('pdfs\\\\chatbot_data_6.pdf',),\n",
       " ('pdfs\\\\chatbot_data_7.pdf',),\n",
       " ('pdfs\\\\chatbot_data_8.pdf',),\n",
       " ('pdfs\\\\chatbot_data_9.pdf',),\n",
       " ('pdfs\\\\chatbot_data_1.pdf',),\n",
       " ('pdfs\\\\chatbot_data_10.pdf',),\n",
       " ('pdfs\\\\chatbot_data_2.pdf',),\n",
       " ('pdfs\\\\chatbot_data_3.pdf',),\n",
       " ('pdfs\\\\chatbot_data_4.pdf',),\n",
       " ('pdfs\\\\chatbot_data_5.pdf',),\n",
       " ('pdfs\\\\chatbot_data_6.pdf',),\n",
       " ('pdfs\\\\chatbot_data_7.pdf',),\n",
       " ('pdfs\\\\chatbot_data_8.pdf',),\n",
       " ('pdfs\\\\chatbot_data_9.pdf',),\n",
       " ('pdfs\\\\chatbot_data_1.pdf',),\n",
       " ('pdfs\\\\chatbot_data_10.pdf',),\n",
       " ('pdfs\\\\chatbot_data_2.pdf',),\n",
       " ('pdfs\\\\chatbot_data_3.pdf',),\n",
       " ('pdfs\\\\chatbot_data_4.pdf',),\n",
       " ('pdfs\\\\chatbot_data_5.pdf',),\n",
       " ('pdfs\\\\chatbot_data_6.pdf',),\n",
       " ('pdfs\\\\chatbot_data_7.pdf',),\n",
       " ('pdfs\\\\chatbot_data_8.pdf',),\n",
       " ('pdfs\\\\chatbot_data_9.pdf',),\n",
       " ('pdfs\\\\chatbot_data_1.pdf',),\n",
       " ('pdfs\\\\chatbot_data_10.pdf',),\n",
       " ('pdfs\\\\chatbot_data_2.pdf',),\n",
       " ('pdfs\\\\chatbot_data_3.pdf',),\n",
       " ('pdfs\\\\chatbot_data_4.pdf',),\n",
       " ('pdfs\\\\chatbot_data_5.pdf',),\n",
       " ('pdfs\\\\chatbot_data_6.pdf',),\n",
       " ('pdfs\\\\chatbot_data_7.pdf',),\n",
       " ('pdfs\\\\chatbot_data_8.pdf',),\n",
       " ('pdfs\\\\chatbot_data_9.pdf',),\n",
       " ('pdfs\\\\chatbot_data_1.pdf',),\n",
       " ('pdfs\\\\chatbot_data_10.pdf',),\n",
       " ('pdfs\\\\chatbot_data_2.pdf',),\n",
       " ('pdfs\\\\chatbot_data_3.pdf',),\n",
       " ('pdfs\\\\chatbot_data_4.pdf',),\n",
       " ('pdfs\\\\chatbot_data_5.pdf',),\n",
       " ('pdfs\\\\chatbot_data_6.pdf',),\n",
       " ('pdfs\\\\chatbot_data_7.pdf',),\n",
       " ('pdfs\\\\chatbot_data_8.pdf',),\n",
       " ('pdfs\\\\chatbot_data_9.pdf',)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# database connect\n",
    "conn = sqlite3.connect(\"database.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# pdf paths read\n",
    "cursor.execute(\"SELECT pdf_path FROM pdf_files\")\n",
    "\n",
    "pdf_paths = cursor.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "pdf_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee02c136-330c-48a6-ba20-6e4348c6fe20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pdfs\\\\chatbot_data_1.pdf',\n",
       " 'pdfs\\\\chatbot_data_10.pdf',\n",
       " 'pdfs\\\\chatbot_data_2.pdf',\n",
       " 'pdfs\\\\chatbot_data_3.pdf',\n",
       " 'pdfs\\\\chatbot_data_4.pdf',\n",
       " 'pdfs\\\\chatbot_data_5.pdf',\n",
       " 'pdfs\\\\chatbot_data_6.pdf',\n",
       " 'pdfs\\\\chatbot_data_7.pdf',\n",
       " 'pdfs\\\\chatbot_data_8.pdf',\n",
       " 'pdfs\\\\chatbot_data_9.pdf',\n",
       " 'pdfs\\\\chatbot_data_1.pdf',\n",
       " 'pdfs\\\\chatbot_data_10.pdf',\n",
       " 'pdfs\\\\chatbot_data_2.pdf',\n",
       " 'pdfs\\\\chatbot_data_3.pdf',\n",
       " 'pdfs\\\\chatbot_data_4.pdf',\n",
       " 'pdfs\\\\chatbot_data_5.pdf',\n",
       " 'pdfs\\\\chatbot_data_6.pdf',\n",
       " 'pdfs\\\\chatbot_data_7.pdf',\n",
       " 'pdfs\\\\chatbot_data_8.pdf',\n",
       " 'pdfs\\\\chatbot_data_9.pdf',\n",
       " 'pdfs\\\\chatbot_data_1.pdf',\n",
       " 'pdfs\\\\chatbot_data_10.pdf',\n",
       " 'pdfs\\\\chatbot_data_2.pdf',\n",
       " 'pdfs\\\\chatbot_data_3.pdf',\n",
       " 'pdfs\\\\chatbot_data_4.pdf',\n",
       " 'pdfs\\\\chatbot_data_5.pdf',\n",
       " 'pdfs\\\\chatbot_data_6.pdf',\n",
       " 'pdfs\\\\chatbot_data_7.pdf',\n",
       " 'pdfs\\\\chatbot_data_8.pdf',\n",
       " 'pdfs\\\\chatbot_data_9.pdf',\n",
       " 'pdfs\\\\chatbot_data_1.pdf',\n",
       " 'pdfs\\\\chatbot_data_10.pdf',\n",
       " 'pdfs\\\\chatbot_data_2.pdf',\n",
       " 'pdfs\\\\chatbot_data_3.pdf',\n",
       " 'pdfs\\\\chatbot_data_4.pdf',\n",
       " 'pdfs\\\\chatbot_data_5.pdf',\n",
       " 'pdfs\\\\chatbot_data_6.pdf',\n",
       " 'pdfs\\\\chatbot_data_7.pdf',\n",
       " 'pdfs\\\\chatbot_data_8.pdf',\n",
       " 'pdfs\\\\chatbot_data_9.pdf',\n",
       " 'pdfs\\\\chatbot_data_1.pdf',\n",
       " 'pdfs\\\\chatbot_data_10.pdf',\n",
       " 'pdfs\\\\chatbot_data_2.pdf',\n",
       " 'pdfs\\\\chatbot_data_3.pdf',\n",
       " 'pdfs\\\\chatbot_data_4.pdf',\n",
       " 'pdfs\\\\chatbot_data_5.pdf',\n",
       " 'pdfs\\\\chatbot_data_6.pdf',\n",
       " 'pdfs\\\\chatbot_data_7.pdf',\n",
       " 'pdfs\\\\chatbot_data_8.pdf',\n",
       " 'pdfs\\\\chatbot_data_9.pdf',\n",
       " 'pdfs\\\\chatbot_data_1.pdf',\n",
       " 'pdfs\\\\chatbot_data_10.pdf',\n",
       " 'pdfs\\\\chatbot_data_2.pdf',\n",
       " 'pdfs\\\\chatbot_data_3.pdf',\n",
       " 'pdfs\\\\chatbot_data_4.pdf',\n",
       " 'pdfs\\\\chatbot_data_5.pdf',\n",
       " 'pdfs\\\\chatbot_data_6.pdf',\n",
       " 'pdfs\\\\chatbot_data_7.pdf',\n",
       " 'pdfs\\\\chatbot_data_8.pdf',\n",
       " 'pdfs\\\\chatbot_data_9.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_paths = [row[0] for row in pdf_paths]\n",
    "pdf_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c18b743-4829-4a38-aec1-d49ae5a75bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def read_pdf(path):\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf7238e-6dc5-4eb2-b04d-e8aa9d7df0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4260"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = \"\"\n",
    "\n",
    "for path in pdf_paths:\n",
    "    all_text += read_pdf(path)\n",
    "\n",
    "len(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c09572-2ab1-4f54-89a8-024ef610f786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello!\\nHi, how can I help you?\\nI want to learn Python.\\nGreat! Let's start with basics.\\nHello\\nHi!\\nCan\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d657d1b-2ce3-4550-a4a6-f490e82b92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3f10f4-3363-41e4-b77e-cf317c23d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\rahul\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (1.2.6)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.12.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4dbfcca-00a5-4ffe-b69b-0c9a3bd0a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=500,     # har chunk 500 characters ka\n",
    "    chunk_overlap=50    # 50 characters overlap\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "540e72db-06c8-4ccf-8fac-465e7d74a977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = text_splitter.split_text(all_text)\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "811837ae-4090-44e0-8c94-5539ad25b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello!\\nHi, how can I help you?\\nI want to learn Python.\\nGreat! Let's start with basics.\\nHello\\nHi!\\nCan you help me?\\nYes, always happy to help.\\nGood morning\\nGood morning! What do you need?\\nTell me about AI.\\nAI means Artificial Intelligence.\\nHi bot\\nHello human!\\nWhat is ML?\\nML is Machine Learning.\\nHey\\nHey there!\\nExplain NLP.\\nNLP stands for Natural Language Processing.\\nHello\\nHi!\\nWhat is a chatbot?\\nA chatbot talks like a human.\\nHi\\nHello!\\nTell me a joke.\\nWhy did the computer smile? Because it had a byte.\\nHello bot\\nHello!\\nHow are you?\\nI am fine, thank you.\\nHi assistant\\nHi!\\nWhat is Python used for?\\nPython is used for AI, ML, web, and more.\\nHey bot\\nHey!\\nExplain deep learning.\\nDeep learning uses neural networks.\\nHello!\\nHi, how can I help you?\\nI want to learn Python.\\nGreat! Let's start with basics.\\nHello\\nHi!\\nCan you help me?\\nYes, always happy to help.\\nGood morning\\nGood morning! What do you need?\\nTell me about AI.\\nAI means Artificial Intelligence.\\nHi bot\\nHello human!\\nWhat is ML?\\nML is Machine Learning.\\nHey\\nHey there!\\nExplain NLP.\\nNLP stands for Natural Language Processing.\\nHello\\nHi!\\nWhat is a chatbot?\\nA chatbot talks like a human.\\nHi\\nHello!\\nTell me a joke.\\nWhy did the computer smile? Because it had a byte.\\nHello bot\\nHello!\\nHow are you?\\nI am fine, thank you.\\nHi assistant\\nHi!\\nWhat is Python used for?\\nPython is used for AI, ML, web, and more.\\nHey bot\\nHey!\\nExplain deep learning.\\nDeep learning uses neural networks.\\nHello!\\nHi, how can I help you?\\nI want to learn Python.\\nGreat! Let's start with basics.\\nHello\\nHi!\\nCan you help me?\\nYes, always happy to help.\\nGood morning\\nGood morning! What do you need?\\nTell me about AI.\\nAI means Artificial Intelligence.\\nHi bot\\nHello human!\\nWhat is ML?\\nML is Machine Learning.\\nHey\\nHey there!\\nExplain NLP.\\nNLP stands for Natural Language Processing.\\nHello\\nHi!\\nWhat is a chatbot?\\nA chatbot talks like a human.\\nHi\\nHello!\\nTell me a joke.\\nWhy did the computer smile? Because it had a byte.\\nHello bot\\nHello!\\nHow are you?\\nI am fine, thank you.\\nHi assistant\\nHi!\\nWhat is Python used for?\\nPython is used for AI, ML, web, and more.\\nHey bot\\nHey!\\nExplain deep learning.\\nDeep learning uses neural networks.\\nHello!\\nHi, how can I help you?\\nI want to learn Python.\\nGreat! Let's start with basics.\\nHello\\nHi!\\nCan you help me?\\nYes, always happy to help.\\nGood morning\\nGood morning! What do you need?\\nTell me about AI.\\nAI means Artificial Intelligence.\\nHi bot\\nHello human!\\nWhat is ML?\\nML is Machine Learning.\\nHey\\nHey there!\\nExplain NLP.\\nNLP stands for Natural Language Processing.\\nHello\\nHi!\\nWhat is a chatbot?\\nA chatbot talks like a human.\\nHi\\nHello!\\nTell me a joke.\\nWhy did the computer smile? Because it had a byte.\\nHello bot\\nHello!\\nHow are you?\\nI am fine, thank you.\\nHi assistant\\nHi!\\nWhat is Python used for?\\nPython is used for AI, ML, web, and more.\\nHey bot\\nHey!\\nExplain deep learning.\\nDeep learning uses neural networks.\\nHello!\\nHi, how can I help you?\\nI want to learn Python.\\nGreat! Let's start with basics.\\nHello\\nHi!\\nCan you help me?\\nYes, always happy to help.\\nGood morning\\nGood morning! What do you need?\\nTell me about AI.\\nAI means Artificial Intelligence.\\nHi bot\\nHello human!\\nWhat is ML?\\nML is Machine Learning.\\nHey\\nHey there!\\nExplain NLP.\\nNLP stands for Natural Language Processing.\\nHello\\nHi!\\nWhat is a chatbot?\\nA chatbot talks like a human.\\nHi\\nHello!\\nTell me a joke.\\nWhy did the computer smile? Because it had a byte.\\nHello bot\\nHello!\\nHow are you?\\nI am fine, thank you.\\nHi assistant\\nHi!\\nWhat is Python used for?\\nPython is used for AI, ML, web, and more.\\nHey bot\\nHey!\\nExplain deep learning.\\nDeep learning uses neural networks.\\nHello!\\nHi, how can I help you?\\nI want to learn Python.\\nGreat! Let's start with basics.\\nHello\\nHi!\\nCan you help me?\\nYes, always happy to help.\\nGood morning\\nGood morning! What do you need?\\nTell me about AI.\\nAI means Artificial Intelligence.\\nHi bot\\nHello human!\\nWhat is ML?\\nML is Machine Learning.\\nHey\\nHey there!\\nExplain NLP.\\nNLP stands for Natural Language Processing.\\nHello\\nHi!\\nWhat is a chatbot?\\nA chatbot talks like a human.\\nHi\\nHello!\\nTell me a joke.\\nWhy did the computer smile? Because it had a byte.\\nHello bot\\nHello!\\nHow are you?\\nI am fine, thank you.\\nHi assistant\\nHi!\\nWhat is Python used for?\\nPython is used for AI, ML, web, and more.\\nHey bot\\nHey!\\nExplain deep learning.\\nDeep learning uses neural networks.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07d07594-a671-40e2-a6f6-427fc1ba6c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\rahul\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\rahul\\anaconda3\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\rahul\\anaconda3\\lib\\site-packages (1.13.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (1.2.6)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.12.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a0726c6-7fd2-4802-8831-8ce7e039424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_5992\\3055314890.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353f4db7d7e248bca4e782e941b1057a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rahul\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60246f380218415089508f93fe150e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af472335832644f492e1c47c0540e4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7a2ddec17840ae84acf662cacde156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78f0c076b36458197b13629ef7b80da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add6c771f46444b58e925fec62c0db2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2741dd4643444fb5b81e143b48bb76cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d29cd434e9475f94dcd72ee061cea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457380c87a3943579cdf299636316d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b548facda48c4ae48fa060e7c5ead60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147aa8266acd4aedb030be61f4e1201f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a386886b-c7b2-462a-a99d-d7c2eada98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_db = FAISS.from_texts(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515cc757-1840-4c75-bd0b-40948b53e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "\n",
      "Hello!\n",
      "Hi, how can I help you?\n",
      "I want to learn Python.\n",
      "Great! Let's start with basics.\n",
      "Hello\n",
      "Hi!\n",
      "Can you help me?\n",
      "Yes, always happy to help.\n",
      "Good morning\n",
      "Good morning! What do you need?\n",
      "Tell me about AI.\n",
      "AI means Artificial Intelligence.\n",
      "Hi bot\n",
      "Hello human!\n",
      "What is ML?\n",
      "ML is Machine Learning.\n",
      "Hey\n",
      "He\n"
     ]
    }
   ],
   "source": [
    "query = \"PDF ka main topic kya hai?\"\n",
    "docs = vector_db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\n--- Result {i} ---\\n\")\n",
    "    print(doc.page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b902e32a-710e-4d5b-b39e-fd5c9bb69000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_chatbot(question, k=3):\n",
    "    docs = vector_db.similarity_search(question, k=k)\n",
    "    \n",
    "    answer = \"\"\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        answer += f\"\\n--- Answer Part {i} ---\\n\"\n",
    "        answer += doc.page_content\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac39d09f-bf09-46a4-a35b-863ff855922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Answer Part 1 ---\n",
      "Hello!\n",
      "Hi, how can I help you?\n",
      "I want to learn Python.\n",
      "Great! Let's start with basics.\n",
      "Hello\n",
      "Hi!\n",
      "Can you help me?\n",
      "Yes, always happy to help.\n",
      "Good morning\n",
      "Good morning! What do you need?\n",
      "Tell me about AI.\n",
      "AI means Artificial Intelligence.\n",
      "Hi bot\n",
      "Hello human!\n",
      "What is ML?\n",
      "ML is Machine Learning.\n",
      "Hey\n",
      "Hey there!\n",
      "Explain NLP.\n",
      "NLP stands for Natural Language Processing.\n",
      "Hello\n",
      "Hi!\n",
      "What is a chatbot?\n",
      "A chatbot talks like a human.\n",
      "Hi\n",
      "Hello!\n",
      "Tell me a joke.\n",
      "Why did the computer smile? Because it had a byte.\n",
      "Hello bot\n",
      "Hello!\n",
      "How are you?\n",
      "I am fine, thank you.\n",
      "Hi assistant\n",
      "Hi!\n",
      "What is Python used for?\n",
      "Python is used for AI, ML, web, and more.\n",
      "Hey bot\n",
      "Hey!\n",
      "Explain deep learning.\n",
      "Deep learning uses neural networks.\n",
      "Hello!\n",
      "Hi, how can I help you?\n",
      "I want to learn Python.\n",
      "Great! Let's start with basics.\n",
      "Hello\n",
      "Hi!\n",
      "Can you help me?\n",
      "Yes, always happy to help.\n",
      "Good morning\n",
      "Good morning! What do you need?\n",
      "Tell me about AI.\n",
      "AI means Artificial Intelligence.\n",
      "Hi bot\n",
      "Hello human!\n",
      "What is ML?\n",
      "ML is Machine Learning.\n",
      "Hey\n",
      "Hey there!\n",
      "Explain NLP.\n",
      "NLP stands for Natural Language Processing.\n",
      "Hello\n",
      "Hi!\n",
      "What is a chatbot?\n",
      "A chatbot talks like a human.\n",
      "Hi\n",
      "Hello!\n",
      "Tell me a joke.\n",
      "Why did the computer smile? Because it had a byte.\n",
      "Hello bot\n",
      "Hello!\n",
      "How are you?\n",
      "I am fine, thank you.\n",
      "Hi assistant\n",
      "Hi!\n",
      "What is Python used for?\n",
      "Python is used for AI, ML, web, and more.\n",
      "Hey bot\n",
      "Hey!\n",
      "Explain deep learning.\n",
      "Deep learning uses neural networks.\n",
      "Hello!\n",
      "Hi, how can I help you?\n",
      "I want to learn Python.\n",
      "Great! Let's start with basics.\n",
      "Hello\n",
      "Hi!\n",
      "Can you help me?\n",
      "Yes, always happy to help.\n",
      "Good morning\n",
      "Good morning! What do you need?\n",
      "Tell me about AI.\n",
      "AI means Artificial Intelligence.\n",
      "Hi bot\n",
      "Hello human!\n",
      "What is ML?\n",
      "ML is Machine Learning.\n",
      "Hey\n",
      "Hey there!\n",
      "Explain NLP.\n",
      "NLP stands for Natural Language Processing.\n",
      "Hello\n",
      "Hi!\n",
      "What is a chatbot?\n",
      "A chatbot talks like a human.\n",
      "Hi\n",
      "Hello!\n",
      "Tell me a joke.\n",
      "Why did the computer smile? Because it had a byte.\n",
      "Hello bot\n",
      "Hello!\n",
      "How are you?\n",
      "I am fine, thank you.\n",
      "Hi assistant\n",
      "Hi!\n",
      "What is Python used for?\n",
      "Python is used for AI, ML, web, and more.\n",
      "Hey bot\n",
      "Hey!\n",
      "Explain deep learning.\n",
      "Deep learning uses neural networks.\n",
      "Hello!\n",
      "Hi, how can I help you?\n",
      "I want to learn Python.\n",
      "Great! Let's start with basics.\n",
      "Hello\n",
      "Hi!\n",
      "Can you help me?\n",
      "Yes, always happy to help.\n",
      "Good morning\n",
      "Good morning! What do you need?\n",
      "Tell me about AI.\n",
      "AI means Artificial Intelligence.\n",
      "Hi bot\n",
      "Hello human!\n",
      "What is ML?\n",
      "ML is Machine Learning.\n",
      "Hey\n",
      "Hey there!\n",
      "Explain NLP.\n",
      "NLP stands for Natural Language Processing.\n",
      "Hello\n",
      "Hi!\n",
      "What is a chatbot?\n",
      "A chatbot talks like a human.\n",
      "Hi\n",
      "Hello!\n",
      "Tell me a joke.\n",
      "Why did the computer smile? Because it had a byte.\n",
      "Hello bot\n",
      "Hello!\n",
      "How are you?\n",
      "I am fine, thank you.\n",
      "Hi assistant\n",
      "Hi!\n",
      "What is Python used for?\n",
      "Python is used for AI, ML, web, and more.\n",
      "Hey bot\n",
      "Hey!\n",
      "Explain deep learning.\n",
      "Deep learning uses neural networks.\n",
      "Hello!\n",
      "Hi, how can I help you?\n",
      "I want to learn Python.\n",
      "Great! Let's start with basics.\n",
      "Hello\n",
      "Hi!\n",
      "Can you help me?\n",
      "Yes, always happy to help.\n",
      "Good morning\n",
      "Good morning! What do you need?\n",
      "Tell me about AI.\n",
      "AI means Artificial Intelligence.\n",
      "Hi bot\n",
      "Hello human!\n",
      "What is ML?\n",
      "ML is Machine Learning.\n",
      "Hey\n",
      "Hey there!\n",
      "Explain NLP.\n",
      "NLP stands for Natural Language Processing.\n",
      "Hello\n",
      "Hi!\n",
      "What is a chatbot?\n",
      "A chatbot talks like a human.\n",
      "Hi\n",
      "Hello!\n",
      "Tell me a joke.\n",
      "Why did the computer smile? Because it had a byte.\n",
      "Hello bot\n",
      "Hello!\n",
      "How are you?\n",
      "I am fine, thank you.\n",
      "Hi assistant\n",
      "Hi!\n",
      "What is Python used for?\n",
      "Python is used for AI, ML, web, and more.\n",
      "Hey bot\n",
      "Hey!\n",
      "Explain deep learning.\n",
      "Deep learning uses neural networks.\n",
      "Hello!\n",
      "Hi, how can I help you?\n",
      "I want to learn Python.\n",
      "Great! Let's start with basics.\n",
      "Hello\n",
      "Hi!\n",
      "Can you help me?\n",
      "Yes, always happy to help.\n",
      "Good morning\n",
      "Good morning! What do you need?\n",
      "Tell me about AI.\n",
      "AI means Artificial Intelligence.\n",
      "Hi bot\n",
      "Hello human!\n",
      "What is ML?\n",
      "ML is Machine Learning.\n",
      "Hey\n",
      "Hey there!\n",
      "Explain NLP.\n",
      "NLP stands for Natural Language Processing.\n",
      "Hello\n",
      "Hi!\n",
      "What is a chatbot?\n",
      "A chatbot talks like a human.\n",
      "Hi\n",
      "Hello!\n",
      "Tell me a joke.\n",
      "Why did the computer smile? Because it had a byte.\n",
      "Hello bot\n",
      "Hello!\n",
      "How are you?\n",
      "I am fine, thank you.\n",
      "Hi assistant\n",
      "Hi!\n",
      "What is Python used for?\n",
      "Python is used for AI, ML, web, and more.\n",
      "Hey bot\n",
      "Hey!\n",
      "Explain deep learning.\n",
      "Deep learning uses neural networks.\n"
     ]
    }
   ],
   "source": [
    "question = \"Is PDF ka main topic kya hai?\"\n",
    "response = pdf_chatbot(question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d557de-d33f-4ddd-8a99-3c200283e216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
